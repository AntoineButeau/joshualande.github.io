---
layout: post
title: "How to Read and Write JSON-formatted Data Using Apache Pig"
comments: true
permalink: read-write-json-apache-pig
---

In this post, I will explain how to use the `JsonStorage` and
`JsonLoader` objects in Apache Pig to read and write 
[JSON](www.json.org)-formatted data.

# Loading JSON-Formatted Data With JsonLoader

The JSON format required by Pig to read and write data
is straightforward.  Each row in the file is
a JSON object where the keys specify the column names and 
the values specify the content.

For example, supposed our table had one column
called `col1`. This data could be stored in `first_table.json` as:

```json
{"col1":"Tacos"}
{"col1":"Tomato Soup"}
{"col1":"Grilled Cheese"}
```

We could load the file using the `JsonLoader`. To do so,
we need to specify the Pig schema of the data as `'col1:chararray'`.
For our example, we would read the data as:

```
first_table = LOAD 'first_table.json' 
    USING JsonLoader('col1:chararray');
```

This creates the table:

|           col1 |
| -------------- |
|          Tacos |
|    Tomato Soup |
| Grilled Cheese |

# Loading Multi-Column Data:

We can load a file with multiple columns just as easily. For example,
if we had the file `second_table.json`

```json
{"food":"Tacos", "person":"Alice", "amount":3}
{"food":"Tomato Soup", "person":"Sarah", "amount":2}
{"food":"Grilled Cheese", "person":"Alex", "amount":5}
```

We could load it by specifying a more complicated schema:

```
second_table = LOAD 'second_table.json' 
    USING JsonLoader('food:chararray, person:chararray, amount:int');
```

This creates the table:

|           food | person | amount |
| -------------- | ------ | ------ |
|          Tacos |  Alice |      3 |
|    Tomato Soup |  Sarah |      2 |
| Grilled Cheese |   Alex |      5 |


# Reading Nested Data

What is nice is that both JSON and Pig support nested data.
For the final example, we will read in a file where each row contains
both a bag of ingredinets and a nested tuple of values.
Reading a bag requires creating a list of dictionaries where
each has the same name. Reading a tuple requires nesting
JSON structs.
For our example, we want to read the file `third_table.json`:

```json
{"recipe":"Tacos", "ingredients": [ {"name":"Beef"}, {"name":"Lettuce"}, {"name":"Cheese"} ], "inventor": {"name":"Alex", "age": 25}}
{"recipe":"Tomato Soup", "ingredients": [ {"name":"Tomatoes"}, {"name":"Milk"} ], "inventor": {"name":"Steve", "age": 23}}
```

We read it as before:

```
third_table = LOAD 'third_table.json' USING JsonLoader('recipe:chararray, ingredients: {(name:chararray)}, inventor: (name:chararray, age:int)');
```

We can see that Pig correctly read in this data with the `DUMP` command:
```
(Tacos,{(Beef),(Lettuce),(Cheese)},(Alex,25))
(Tomato Soup,{(Tomatoes),(Milk)},(Steve,23))
```

# Writing JSON-Formatted Data in Pig

Finally, it is easy to store data from Pig to JSON using the
`JsonStorage` command. As a simple example, imagine loading in the
table `first_table.dat`:

```
cat > first_table.dat
Tacos
Tomato Soup
Grilled Cheese
```

We can read it in Pig using `PigStorage`, and then save the table
to JSON using `JsonStorage`:

```
first_table = LOAD 'first_table.dat' Using PigStorage() AS (col1:chararray);

STORE first_table INTO 'first_table.json' USING JsonStorage();
```

As is the convetion of HDFS, the output by Pig is a folder called
'first_table.json'. Inside the folder is a file called `part-m-00000`
which contains the data with the expected schema:

```json
{"col1":"Tacos"}
{"col1":"Tomato Soup"}
{"col1":"Grilled Cheese"}
```

Note that Pig wrote out an intermediate file into `first_table.json`
folder called: called `.pig_schema`:
```
{"fields":[{"name":"col1","type":55,"description":"autogenerated from Pig Field Schema","schema":null}],"version":0,"sortKeys":[],"sortKeyOrders":[]}
```

This file allows the table to be read in by subsequent Pig jobs
without explicitly specifying the schema with the `JsonLoader`
command.

